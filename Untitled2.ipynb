{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pennylane'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-db351cd9bf0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpennylane\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mqml\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpennylane\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpennylane\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pennylane'"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "\n",
    "try:\n",
    "    dev = qml.device('strawberryfields.fock', wires=1, cutoff_dim=10)    \n",
    "except:\n",
    "    print(\"To run this demo you need to install the strawberryfields plugin...\")\n",
    "\n",
    "\n",
    "def layer(v):\n",
    "    \"\"\" Single layer of the quantum neural net.\n",
    "    Args:\n",
    "        v (array[float]): array of variables for one layer\n",
    "    \"\"\"\n",
    "    # Matrix multiplication of input layer\n",
    "    qml.Rotation(v[0], wires=0)\n",
    "    qml.Squeezing(v[1], 0., wires=0)\n",
    "    qml.Rotation(v[2], wires=0)\n",
    "\n",
    "    # Bias\n",
    "    qml.Displacement(v[3], 0., wires=0)\n",
    "\n",
    "    # Element-wise nonlinear transformation\n",
    "    qml.Kerr(v[4], wires=0)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def quantum_neural_net(var, x=None):\n",
    "    \"\"\"The quantum neural net variational circuit.\n",
    "    Args:\n",
    "        var (array[float]): array of variables\n",
    "        x (array[float]): single input vector\n",
    "    Returns:\n",
    "        float: expectation of Homodyne measurement on Mode 0\n",
    "    \"\"\"\n",
    "    # Encode input x into quantum state\n",
    "    qml.Displacement(x, 0., wires=0)\n",
    "\n",
    "    # \"layer\" subcircuits\n",
    "    for v in var:\n",
    "        layer(v)\n",
    "\n",
    "    return qml.expval.X(0)\n",
    "\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    \"\"\" Square loss function\n",
    "    Args:\n",
    "        labels (array[float]): 1-d array of labels\n",
    "        predictions (array[float]): 1-d array of predictions\n",
    "    Returns:\n",
    "        float: square loss\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def cost(var, features, labels):\n",
    "    \"\"\"Cost function to be minimized.\n",
    "    Args:\n",
    "        var (array[float]): array of variables\n",
    "        features (array[float]): 2-d array of input vectors\n",
    "        labels (array[float]): 1-d array of targets\n",
    "    Returns:\n",
    "        float: loss\n",
    "    \"\"\"\n",
    "    # Compute prediction for each input in data batch\n",
    "    preds = [quantum_neural_net(var, x=x) for x in features]\n",
    "\n",
    "    return square_loss(labels, preds)\n",
    "\n",
    "\n",
    "# load function data\n",
    "data = np.loadtxt(\"data/sine.txt\")\n",
    "X = data[:, 0]\n",
    "Y = data[:, 1]\n",
    "\n",
    "# initialize weights\n",
    "np.random.seed(0)\n",
    "num_layers = 4\n",
    "var_init = 0.05 * np.random.randn(num_layers, 5)\n",
    "\n",
    "# create optimizer\n",
    "opt = AdamOptimizer(0.01, beta1=0.9, beta2=0.999)\n",
    "\n",
    "# train\n",
    "var = var_init\n",
    "for it in range(500):\n",
    "    var = opt.step(lambda v: cost(v, X, Y), var)\n",
    "    \n",
    "print(\"Iter: {:5d} | Cost: {:0.7f} \".format(it + 1, cost(var, X, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
